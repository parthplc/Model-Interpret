{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lime\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "# this is the name of the model we want to evaluate on \n",
    "# huggingface.com/models or alternatively you could train your own\n",
    "MODEL=\"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_adapter(texts: List[str]):\n",
    "    \n",
    "    all_scores = []\n",
    "\n",
    "    for i in range(0, len(texts), 64):\n",
    "\n",
    "        batch = texts[i:i+64]\n",
    "        \n",
    "        # use bert encoder to tokenize text \n",
    "        encoded_input = tokenizer(batch, \n",
    "          return_tensors='pt', \n",
    "          padding=True, \n",
    "          truncation=True, \n",
    "          max_length=model.config.max_position_embeddings-2)\n",
    "\n",
    "        # run the model\n",
    "        output = model(**encoded_input)\n",
    "        # by default this model gives raw logits rather \n",
    "        # than a nice smooth softmax so we apply it ourselves here\n",
    "        scores = output[0].softmax(1).detach().numpy()\n",
    "\n",
    "        all_scores.extend(scores)\n",
    "\n",
    "    return np.array(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names=list(model.config.id2label.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 star', '2 stars', '3 stars', '4 stars', '5 stars']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = LimeTextExplainer(class_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lime.lime_text.LimeTextExplainer at 0x16b65d839d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str_to_predict = \"surprising increase in revenue in spite of decrease in market share\"\n",
    "# exp = explainer.explain_instance(str_to_predict, model_adapter, num_features=5, num_samples=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=1 star\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.001</b>, score <b>-6.834</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.78%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.468\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -6.366\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 94.48%); opacity: 0.81\" title=\"-0.093\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.88%); opacity: 0.85\" title=\"-0.357\">restaurant</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.29%); opacity: 0.83\" title=\"0.209\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 66.93%); opacity: 0.95\" title=\"-1.203\">amazing</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 93.23%); opacity: 0.82\" title=\"-0.125\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 73.43%); opacity: 0.91\" title=\"-0.880\">quality</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.83%); opacity: 0.81\" title=\"0.085\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.75%); opacity: 0.83\" title=\"-0.226\">their</span><span style=\"opacity: 0.80\"> \n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 90.31%); opacity: 0.83\" title=\"-0.208\">food</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.86%); opacity: 0.81\" title=\"0.084\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 63.45%); opacity: 0.98\" title=\"-1.388\">exceptional</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 91.01%); opacity: 0.82\" title=\"-0.187\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.90%); opacity: 0.85\" title=\"-0.356\">waiters</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.42%); opacity: 0.84\" title=\"0.337\">were</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.80%); opacity: 0.82\" title=\"0.136\">so</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.88%); opacity: 0.84\" title=\"-0.321\">polite</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=2 stars\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.002</b>, score <b>-6.109</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 97.12%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.400\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 81.47%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -5.709\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 90.81%); opacity: 0.82\" title=\"-0.193\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.82%); opacity: 0.84\" title=\"-0.323\">restaurant</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.91%); opacity: 0.83\" title=\"0.221\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-1.578\">amazing</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 97.17%); opacity: 0.80\" title=\"-0.036\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.39%); opacity: 0.87\" title=\"-0.570\">quality</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.45%); opacity: 0.84\" title=\"0.301\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.83%); opacity: 0.81\" title=\"-0.109\">their</span><span style=\"opacity: 0.80\"> \n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 91.60%); opacity: 0.82\" title=\"-0.170\">food</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.51%); opacity: 0.83\" title=\"0.266\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.04%); opacity: 1.00\" title=\"-1.576\">exceptional</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 94.71%); opacity: 0.81\" title=\"-0.088\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.81%); opacity: 0.81\" title=\"-0.063\">waiters</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.68%); opacity: 0.84\" title=\"0.328\">were</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.38%); opacity: 0.83\" title=\"0.270\">so</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.11%); opacity: 0.86\" title=\"-0.461\">polite</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=3 stars\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.013</b>, score <b>-4.219</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 97.13%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.397\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.01%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.822\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 99.00%); opacity: 0.80\" title=\"-0.008\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.70%); opacity: 0.80\" title=\"0.027\">restaurant</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.37%); opacity: 0.86\" title=\"0.490\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 66.11%); opacity: 0.96\" title=\"-1.246\">amazing</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 95.96%); opacity: 0.81\" title=\"0.060\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.01%); opacity: 0.83\" title=\"-0.249\">quality</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.09%); opacity: 0.83\" title=\"0.247\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.51%); opacity: 0.81\" title=\"0.117\">their</span><span style=\"opacity: 0.80\"> \n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 90.83%); opacity: 0.82\" title=\"0.193\">food</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.56%); opacity: 0.84\" title=\"0.332\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 64.30%); opacity: 0.97\" title=\"-1.342\">exceptional</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 95.90%); opacity: 0.81\" title=\"-0.061\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.18%); opacity: 0.80\" title=\"-0.036\">waiters</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.91%); opacity: 0.81\" title=\"-0.107\">were</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.04%); opacity: 0.83\" title=\"-0.248\">so</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.75%); opacity: 0.89\" title=\"-0.727\">polite</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=4 stars\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.218</b>, score <b>-1.159</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.45%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.539\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.08%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.621\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 96.45%); opacity: 0.81\" title=\"0.050\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.54%); opacity: 0.83\" title=\"0.265\">restaurant</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.58%); opacity: 0.85\" title=\"0.367\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.38%); opacity: 0.85\" title=\"-0.375\">amazing</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 96.04%); opacity: 0.81\" title=\"0.058\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.13%); opacity: 0.80\" title=\"0.037\">quality</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(120, 100.00%, 92.24%); opacity: 0.82\" title=\"0.152\">their</span><span style=\"opacity: 0.80\"> \n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 89.34%); opacity: 0.83\" title=\"0.239\">food</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.68%); opacity: 0.82\" title=\"0.168\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.54%); opacity: 0.83\" title=\"-0.201\">exceptional</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 96.74%); opacity: 0.81\" title=\"0.044\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.09%); opacity: 0.82\" title=\"0.185\">waiters</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.70%); opacity: 0.80\" title=\"-0.012\">were</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.10%); opacity: 0.84\" title=\"-0.314\">so</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.04%); opacity: 0.82\" title=\"-0.157\">polite</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=5 stars\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.766</b>, score <b>1.648</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.59%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.169\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.53%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.521\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 98.11%); opacity: 0.80\" title=\"-0.020\">the</span><span style=\"opacity: 0.80\"> restaurant </span><span style=\"background-color: hsl(0, 100.00%, 82.16%); opacity: 0.86\" title=\"-0.498\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 69.11%); opacity: 0.94\" title=\"1.091\">amazing</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 89.25%); opacity: 0.83\" title=\"-0.242\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.18%); opacity: 0.84\" title=\"0.311\">quality</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.98%); opacity: 0.82\" title=\"-0.132\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.65%); opacity: 0.81\" title=\"-0.089\">their</span><span style=\"opacity: 0.80\"> \n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 94.24%); opacity: 0.81\" title=\"-0.099\">food</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.68%); opacity: 0.83\" title=\"-0.228\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 69.54%); opacity: 0.94\" title=\"1.070\">exceptional</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 95.84%); opacity: 0.81\" title=\"-0.062\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.26%); opacity: 0.80\" title=\"-0.005\">waiters</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.01%); opacity: 0.83\" title=\"0.218\">were</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.02%); opacity: 0.87\" title=\"0.544\">so</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.35%); opacity: 0.88\" title=\"0.657\">polite</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator=\"SGDClassifier(alpha=0.001, loss='log', penalty='elasticnet',\\n              random_state=RandomState(MT19937) at 0x23444ACF740)\", description=None, error=None, method='linear model', is_regression=False, targets=[TargetExplanation(target='1 star', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='were so', weight=0.4412142792788092, std=None, value=1.0), FeatureWeight(feature='food was', weight=0.26752107341372183, std=None, value=1.0), FeatureWeight(feature='restaurant was', weight=0.266566087992046, std=None, value=1.0), FeatureWeight(feature='waiters were', weight=0.20671345225968546, std=None, value=1.0), FeatureWeight(feature='their food', weight=0.19225542650789543, std=None, value=1.0), FeatureWeight(feature='of their', weight=0.17089439768401474, std=None, value=1.0), FeatureWeight(feature='so polite', weight=0.16971856137145255, std=None, value=1.0), FeatureWeight(feature='the restaurant', weight=0.09395728540023118, std=None, value=1.0), FeatureWeight(feature='the quality', weight=0.06235816727168654, std=None, value=1.0), FeatureWeight(feature='was amazing', weight=0.04621754955053717, std=None, value=1.0), FeatureWeight(feature='quality of', weight=0.036982483291333315, std=None, value=1.0)], neg=[FeatureWeight(feature='exceptional', weight=-1.3083460073861428, std=None, value=1.0), FeatureWeight(feature='amazing', weight=-1.2489714603173006, std=None, value=1.0), FeatureWeight(feature='quality', weight=-0.9791490505974169, std=None, value=1.0), FeatureWeight(feature='restaurant', weight=-0.7171043876100933, std=None, value=1.0), FeatureWeight(feature='food', weight=-0.6679038114428723, std=None, value=1.0), FeatureWeight(feature='their', weight=-0.5886911093430724, std=None, value=1.0), FeatureWeight(feature='waiters', weight=-0.5624537628909229, std=None, value=1.0), FeatureWeight(feature='the', weight=-0.561238646099185, std=None, value=3.0), FeatureWeight(feature='polite', weight=-0.4909223929633988, std=None, value=1.0), FeatureWeight(feature='so', weight=-0.474632552661918, std=None, value=1.0), FeatureWeight(feature='<BIAS>', weight=-0.46817511726941313, std=None, value=1.0), FeatureWeight(feature='were', weight=-0.3105891970589915, std=None, value=1.0), FeatureWeight(feature='was', weight=-0.20789884677179046, std=None, value=2.0), FeatureWeight(feature='of', weight=-0.12298547156907863, std=None, value=1.0), FeatureWeight(feature='was exceptional', weight=-0.07927481966138583, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.0009819658649170202, score=-6.833937869621569, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document='the restaurant was amazing, the quality of their \\nfood was exceptional. the waiters were so polite.', spans=[('the', [(0, 3)], -0.561238646099185), ('restaurant', [(4, 14)], -0.7171043876100933), ('was', [(15, 18)], -0.20789884677179046), ('amazing', [(19, 26)], -1.2489714603173006), ('the', [(28, 31)], -0.561238646099185), ('quality', [(32, 39)], -0.9791490505974169), ('of', [(40, 42)], -0.12298547156907863), ('their', [(43, 48)], -0.5886911093430724), ('food', [(50, 54)], -0.6679038114428723), ('was', [(55, 58)], -0.20789884677179046), ('exceptional', [(59, 70)], -1.3083460073861428), ('the', [(72, 75)], -0.561238646099185), ('waiters', [(76, 83)], -0.5624537628909229), ('were', [(84, 88)], -0.3105891970589915), ('so', [(89, 91)], -0.474632552661918), ('polite', [(92, 98)], -0.4909223929633988), ('the restaurant', [(0, 3), (4, 14)], 0.09395728540023118), ('restaurant was', [(4, 14), (15, 18)], 0.266566087992046), ('was amazing', [(15, 18), (19, 26)], 0.04621754955053717), ('the quality', [(28, 31), (32, 39)], 0.06235816727168654), ('quality of', [(32, 39), (40, 42)], 0.036982483291333315), ('of their', [(40, 42), (43, 48)], 0.17089439768401474), ('their food', [(43, 48), (50, 54)], 0.19225542650789543), ('food was', [(50, 54), (55, 58)], 0.26752107341372183), ('was exceptional', [(55, 58), (59, 70)], -0.07927481966138583), ('waiters were', [(76, 83), (84, 88)], 0.20671345225968546), ('were so', [(84, 88), (89, 91)], 0.4412142792788092), ('so polite', [(89, 91), (92, 98)], 0.16971856137145255)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[], neg=[FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=-6.365762752352155, std=None, value=None), FeatureWeight(feature='<BIAS>', weight=-0.46817511726941313, std=None, value=1.0)], pos_remaining=0, neg_remaining=0)), heatmap=None), TargetExplanation(target='2 stars', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='were so', weight=0.3687584351354405, std=None, value=1.0), FeatureWeight(feature='food was', weight=0.28182130478782796, std=None, value=1.0), FeatureWeight(feature='restaurant was', weight=0.23694730908198505, std=None, value=1.0), FeatureWeight(feature='waiters were', weight=0.21363431305973524, std=None, value=1.0), FeatureWeight(feature='quality of', weight=0.20779481726471227, std=None, value=1.0), FeatureWeight(feature='the waiters', weight=0.20231925231831172, std=None, value=1.0), FeatureWeight(feature='their food', weight=0.18114183804667405, std=None, value=1.0), FeatureWeight(feature='of their', weight=0.17536148206666208, std=None, value=1.0), FeatureWeight(feature='the quality', weight=0.157072264831271, std=None, value=1.0)], neg=[FeatureWeight(feature='amazing', weight=-1.5783751972217896, std=None, value=1.0), FeatureWeight(feature='exceptional', weight=-1.4790309783432105, std=None, value=1.0), FeatureWeight(feature='quality', weight=-0.9347689615679214, std=None, value=1.0), FeatureWeight(feature='food', weight=-0.6327993132635227, std=None, value=1.0), FeatureWeight(feature='the', weight=-0.5788250220187663, std=None, value=3.0), FeatureWeight(feature='restaurant', weight=-0.5602856269944528, std=None, value=1.0), FeatureWeight(feature='waiters', weight=-0.4789001349410293, std=None, value=1.0), FeatureWeight(feature='their', weight=-0.4658734232822864, std=None, value=1.0), FeatureWeight(feature='polite', weight=-0.46060290921327995, std=None, value=1.0), FeatureWeight(feature='<BIAS>', weight=-0.40017546323721404, std=None, value=1.0), FeatureWeight(feature='were', weight=-0.25430255925416345, std=None, value=1.0), FeatureWeight(feature='so', weight=-0.09871439184564404, std=None, value=1.0), FeatureWeight(feature='exceptional the', weight=-0.09697973820214978, std=None, value=1.0), FeatureWeight(feature='of', weight=-0.08167691136359298, std=None, value=1.0), FeatureWeight(feature='was', weight=-0.032406212118967, std=None, value=2.0)], pos_remaining=0, neg_remaining=0), proba=0.0020253220785572366, score=-6.108865826275371, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document='the restaurant was amazing, the quality of their \\nfood was exceptional. the waiters were so polite.', spans=[('the', [(0, 3)], -0.5788250220187663), ('restaurant', [(4, 14)], -0.5602856269944528), ('was', [(15, 18)], -0.032406212118967), ('amazing', [(19, 26)], -1.5783751972217896), ('the', [(28, 31)], -0.5788250220187663), ('quality', [(32, 39)], -0.9347689615679214), ('of', [(40, 42)], -0.08167691136359298), ('their', [(43, 48)], -0.4658734232822864), ('food', [(50, 54)], -0.6327993132635227), ('was', [(55, 58)], -0.032406212118967), ('exceptional', [(59, 70)], -1.4790309783432105), ('the', [(72, 75)], -0.5788250220187663), ('waiters', [(76, 83)], -0.4789001349410293), ('were', [(84, 88)], -0.25430255925416345), ('so', [(89, 91)], -0.09871439184564404), ('polite', [(92, 98)], -0.46060290921327995), ('restaurant was', [(4, 14), (15, 18)], 0.23694730908198505), ('the quality', [(28, 31), (32, 39)], 0.157072264831271), ('quality of', [(32, 39), (40, 42)], 0.20779481726471227), ('of their', [(40, 42), (43, 48)], 0.17536148206666208), ('their food', [(43, 48), (50, 54)], 0.18114183804667405), ('food was', [(50, 54), (55, 58)], 0.28182130478782796), ('exceptional the', [(59, 70), (72, 75)], -0.09697973820214978), ('the waiters', [(72, 75), (76, 83)], 0.20231925231831172), ('waiters were', [(76, 83), (84, 88)], 0.21363431305973524), ('were so', [(84, 88), (89, 91)], 0.3687584351354405)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[], neg=[FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=-5.708690363038157, std=None, value=None), FeatureWeight(feature='<BIAS>', weight=-0.40017546323721404, std=None, value=1.0)], pos_remaining=0, neg_remaining=0)), heatmap=None), TargetExplanation(target='3 stars', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='so', weight=0.37328879922708785, std=None, value=1.0), FeatureWeight(feature='was amazing', weight=0.297306855613012, std=None, value=1.0), FeatureWeight(feature='food was', weight=0.29661721704498895, std=None, value=1.0), FeatureWeight(feature='their food', weight=0.21834819946542033, std=None, value=1.0), FeatureWeight(feature='the quality', weight=0.215757628162897, std=None, value=1.0), FeatureWeight(feature='waiters were', weight=0.1912385413954662, std=None, value=1.0), FeatureWeight(feature='restaurant was', weight=0.15656173982130678, std=None, value=1.0), FeatureWeight(feature='the restaurant', weight=0.14797243625683293, std=None, value=1.0), FeatureWeight(feature='quality of', weight=0.14264912543429942, std=None, value=1.0), FeatureWeight(feature='of their', weight=0.12312764745359953, std=None, value=1.0), FeatureWeight(feature='the waiters', weight=0.09515209208809655, std=None, value=1.0), FeatureWeight(feature='was', weight=0.07169380833545574, std=None, value=2.0)], neg=[FeatureWeight(feature='amazing', weight=-1.5430523131452285, std=None, value=1.0), FeatureWeight(feature='exceptional', weight=-1.3418851039304842, std=None, value=1.0), FeatureWeight(feature='quality', weight=-0.6076663429775768, std=None, value=1.0), FeatureWeight(feature='so polite', weight=-0.5499925348438072, std=None, value=1.0), FeatureWeight(feature='the', weight=-0.46821278223214663, std=None, value=3.0), FeatureWeight(feature='<BIAS>', weight=-0.3973113230934473, std=None, value=1.0), FeatureWeight(feature='food', weight=-0.3224518838953579, std=None, value=1.0), FeatureWeight(feature='waiters', weight=-0.3220949693051252, std=None, value=1.0), FeatureWeight(feature='restaurant', weight=-0.2779002036079688, std=None, value=1.0), FeatureWeight(feature='were', weight=-0.22670218335080222, std=None, value=1.0), FeatureWeight(feature='their', weight=-0.22404977692950842, std=None, value=1.0), FeatureWeight(feature='polite', weight=-0.17712570659886517, std=None, value=1.0), FeatureWeight(feature='were so', weight=-0.07174581836680805, std=None, value=1.0), FeatureWeight(feature='of', weight=-0.018921718697862907, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.013234356545440373, score=-4.2193985706765265, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document='the restaurant was amazing, the quality of their \\nfood was exceptional. the waiters were so polite.', spans=[('the', [(0, 3)], -0.46821278223214663), ('restaurant', [(4, 14)], -0.2779002036079688), ('was', [(15, 18)], 0.07169380833545574), ('amazing', [(19, 26)], -1.5430523131452285), ('the', [(28, 31)], -0.46821278223214663), ('quality', [(32, 39)], -0.6076663429775768), ('of', [(40, 42)], -0.018921718697862907), ('their', [(43, 48)], -0.22404977692950842), ('food', [(50, 54)], -0.3224518838953579), ('was', [(55, 58)], 0.07169380833545574), ('exceptional', [(59, 70)], -1.3418851039304842), ('the', [(72, 75)], -0.46821278223214663), ('waiters', [(76, 83)], -0.3220949693051252), ('were', [(84, 88)], -0.22670218335080222), ('so', [(89, 91)], 0.37328879922708785), ('polite', [(92, 98)], -0.17712570659886517), ('the restaurant', [(0, 3), (4, 14)], 0.14797243625683293), ('restaurant was', [(4, 14), (15, 18)], 0.15656173982130678), ('was amazing', [(15, 18), (19, 26)], 0.297306855613012), ('the quality', [(28, 31), (32, 39)], 0.215757628162897), ('quality of', [(32, 39), (40, 42)], 0.14264912543429942), ('of their', [(40, 42), (43, 48)], 0.12312764745359953), ('their food', [(43, 48), (50, 54)], 0.21834819946542033), ('food was', [(50, 54), (55, 58)], 0.29661721704498895), ('the waiters', [(72, 75), (76, 83)], 0.09515209208809655), ('waiters were', [(76, 83), (84, 88)], 0.1912385413954662), ('were so', [(84, 88), (89, 91)], -0.07174581836680805), ('so polite', [(89, 91), (92, 98)], -0.5499925348438072)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[], neg=[FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=-3.82208724758308, std=None, value=None), FeatureWeight(feature='<BIAS>', weight=-0.3973113230934473, std=None, value=1.0)], pos_remaining=0, neg_remaining=0)), heatmap=None), TargetExplanation(target='4 stars', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='was amazing', weight=0.24063250771685435, std=None, value=1.0), FeatureWeight(feature='their food', weight=0.1515772385387, std=None, value=1.0), FeatureWeight(feature='the quality', weight=0.1399818513805465, std=None, value=1.0), FeatureWeight(feature='the restaurant', weight=0.13787874014492774, std=None, value=1.0), FeatureWeight(feature='restaurant was', weight=0.1268433135454435, std=None, value=1.0), FeatureWeight(feature='the waiters', weight=0.12309277037766057, std=None, value=1.0), FeatureWeight(feature='waiters were', weight=0.09734080413820682, std=None, value=1.0), FeatureWeight(feature='food was', weight=0.0869252010404829, std=None, value=1.0), FeatureWeight(feature='was exceptional', weight=0.08062590525808605, std=None, value=1.0), FeatureWeight(feature='exceptional the', weight=0.009074556454012622, std=None, value=1.0), FeatureWeight(feature='amazing the', weight=0.006158831321800481, std=None, value=1.0)], neg=[FeatureWeight(feature='amazing', weight=-0.6215482013799933, std=None, value=1.0), FeatureWeight(feature='<BIAS>', weight=-0.6208851731272248, std=None, value=1.0), FeatureWeight(feature='exceptional', weight=-0.29088276664173235, std=None, value=1.0), FeatureWeight(feature='the', weight=-0.26449962830897517, std=None, value=3.0), FeatureWeight(feature='so polite', weight=-0.15732513067254014, std=None, value=1.0), FeatureWeight(feature='so', weight=-0.15620445986313106, std=None, value=1.0), FeatureWeight(feature='were', weight=-0.10913166927840638, std=None, value=1.0), FeatureWeight(feature='quality', weight=-0.10333919110091695, std=None, value=1.0), FeatureWeight(feature='waiters', weight=-0.03571463874678359, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.2180202136415915, score=-1.159399139202982, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document='the restaurant was amazing, the quality of their \\nfood was exceptional. the waiters were so polite.', spans=[('the', [(0, 3)], -0.26449962830897517), ('amazing', [(19, 26)], -0.6215482013799933), ('the', [(28, 31)], -0.26449962830897517), ('quality', [(32, 39)], -0.10333919110091695), ('exceptional', [(59, 70)], -0.29088276664173235), ('the', [(72, 75)], -0.26449962830897517), ('waiters', [(76, 83)], -0.03571463874678359), ('were', [(84, 88)], -0.10913166927840638), ('so', [(89, 91)], -0.15620445986313106), ('the restaurant', [(0, 3), (4, 14)], 0.13787874014492774), ('restaurant was', [(4, 14), (15, 18)], 0.1268433135454435), ('was amazing', [(15, 18), (19, 26)], 0.24063250771685435), ('amazing the', [(19, 26), (28, 31)], 0.006158831321800481), ('the quality', [(28, 31), (32, 39)], 0.1399818513805465), ('their food', [(43, 48), (50, 54)], 0.1515772385387), ('food was', [(50, 54), (55, 58)], 0.0869252010404829), ('was exceptional', [(55, 58), (59, 70)], 0.08062590525808605), ('exceptional the', [(59, 70), (72, 75)], 0.009074556454012622), ('the waiters', [(72, 75), (76, 83)], 0.12309277037766057), ('waiters were', [(76, 83), (84, 88)], 0.09734080413820682), ('so polite', [(89, 91), (92, 98)], -0.15732513067254014)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[], neg=[FeatureWeight(feature='<BIAS>', weight=-0.6208851731272248, std=None, value=1.0), FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=-0.5385139660757575, std=None, value=None)], pos_remaining=0, neg_remaining=0)), heatmap=None), TargetExplanation(target='5 stars', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='amazing', weight=1.4166616343102318, std=None, value=1.0), FeatureWeight(feature='exceptional', weight=1.1116493929667317, std=None, value=1.0), FeatureWeight(feature='so polite', weight=0.71839952646525, std=None, value=1.0), FeatureWeight(feature='quality', weight=0.46032604083818623, std=None, value=1.0), FeatureWeight(feature='were so', weight=0.24902157514206438, std=None, value=1.0), FeatureWeight(feature='of their', weight=0.08236797863897373, std=None, value=1.0), FeatureWeight(feature='food', weight=0.0558607067265137, std=None, value=1.0), FeatureWeight(feature='waiters', weight=0.02617745978942457, std=None, value=1.0), FeatureWeight(feature='food was', weight=0.01654520820628055, std=None, value=1.0)], neg=[FeatureWeight(feature='<BIAS>', weight=-0.5209352118853326, std=None, value=1.0), FeatureWeight(feature='was', weight=-0.48869249339855936, std=None, value=2.0), FeatureWeight(feature='so', weight=-0.423226618900104, std=None, value=1.0), FeatureWeight(feature='was amazing', weight=-0.25354612144773503, std=None, value=1.0), FeatureWeight(feature='of', weight=-0.2138966475477286, std=None, value=1.0), FeatureWeight(feature='their food', weight=-0.17140724010730807, std=None, value=1.0), FeatureWeight(feature='the quality', weight=-0.14962242819710428, std=None, value=1.0), FeatureWeight(feature='amazing the', weight=-0.07179925678814661, std=None, value=1.0), FeatureWeight(feature='polite', weight=-0.06184756173850316, std=None, value=1.0), FeatureWeight(feature='the', weight=-0.06032069433534206, std=None, value=3.0), FeatureWeight(feature='exceptional the', weight=-0.04214936922012963, std=None, value=1.0), FeatureWeight(feature='waiters were', weight=-0.03142944168923971, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.765738141869494, score=1.6481364378284238, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document='the restaurant was amazing, the quality of their \\nfood was exceptional. the waiters were so polite.', spans=[('the', [(0, 3)], -0.06032069433534206), ('was', [(15, 18)], -0.48869249339855936), ('amazing', [(19, 26)], 1.4166616343102318), ('the', [(28, 31)], -0.06032069433534206), ('quality', [(32, 39)], 0.46032604083818623), ('of', [(40, 42)], -0.2138966475477286), ('food', [(50, 54)], 0.0558607067265137), ('was', [(55, 58)], -0.48869249339855936), ('exceptional', [(59, 70)], 1.1116493929667317), ('the', [(72, 75)], -0.06032069433534206), ('waiters', [(76, 83)], 0.02617745978942457), ('so', [(89, 91)], -0.423226618900104), ('polite', [(92, 98)], -0.06184756173850316), ('was amazing', [(15, 18), (19, 26)], -0.25354612144773503), ('amazing the', [(19, 26), (28, 31)], -0.07179925678814661), ('the quality', [(28, 31), (32, 39)], -0.14962242819710428), ('of their', [(40, 42), (43, 48)], 0.08236797863897373), ('their food', [(43, 48), (50, 54)], -0.17140724010730807), ('food was', [(50, 54), (55, 58)], 0.01654520820628055), ('exceptional the', [(59, 70), (72, 75)], -0.04214936922012963), ('waiters were', [(76, 83), (84, 88)], -0.03142944168923971), ('were so', [(84, 88), (89, 91)], 0.24902157514206438), ('so polite', [(89, 91), (92, 98)], 0.71839952646525)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=2.1690716497137554, std=None, value=None)], neg=[FeatureWeight(feature='<BIAS>', weight=-0.5209352118853326, std=None, value=1.0)], pos_remaining=0, neg_remaining=0)), heatmap=None)], feature_importances=None, decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eli5.lime import TextExplainer\n",
    "\n",
    "te = TextExplainer(n_samples=5000, random_state=42)\n",
    "te.fit(\"\"\"The restaurant was amazing, the quality of their \n",
    "food was exceptional. The waiters were so polite.\"\"\", model_adapter)\n",
    "te.explain_prediction(target_names=list(model.config.id2label.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import lime\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "# class_names = ['positive','negative', 'neutral']\n",
    "\n",
    "# def predictor(texts):\n",
    "#     outputs = model(**tokenizer(texts, return_tensors=\"pt\", padding=True))\n",
    "#     probas = F.softmax(outputs.logits).detach().numpy()\n",
    "#     return probas\n",
    "\n",
    "# explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "# str_to_predict = \"surprising increase in revenue in spite of decrease in market share\"\n",
    "# exp = explainer.explain_instance(str_to_predict, predictor, num_features=20, num_samples=2000)\n",
    "# exp.show_in_notebook(text=str_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c81af8a91b224be140c3959e2e732bf24251c1718669fabf8161fc3ab8e9a1d5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
